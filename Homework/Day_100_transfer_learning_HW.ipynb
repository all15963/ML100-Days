{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128 \n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 50 # 訓練的 epochs 數量\n",
    "\n",
    "# 讀取資料並檢視\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='wrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor=\"val_acc\", patience=10, verbose=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.5, \n",
    "                              min_lr=1e-12, \n",
    "                              monitor='val_loss', \n",
    "                              patience=5, \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 48)        13872     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 64)        27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 80)        46160     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 80)        320       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 24, 24, 80)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 80)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 80)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 96)        69216     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 10, 10, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10, 10, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 112)         96880     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 112)         448       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 112)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 112)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 128)         129152    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 144)         166032    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 144)         576       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4, 4, 144)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 144)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 2, 144)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 915,114\n",
      "Trainable params: 913,706\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立 ResNet 模型\n",
    "from model_builder import CNNmodel # 這是從 resnet_builder.py 中直接 import 撰寫好的 resnet 函數\n",
    "model = CNNmodel(input_shape=(32,32,3)) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 1.5028 - acc: 0.4453 - val_loss: 1.2866 - val_acc: 0.5579\n",
      "Epoch 2/50\n",
      "1562/1562 [==============================] - 58s 37ms/step - loss: 1.1095 - acc: 0.6061 - val_loss: 0.9976 - val_acc: 0.6483\n",
      "Epoch 3/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.9535 - acc: 0.6669 - val_loss: 1.1456 - val_acc: 0.6305\n",
      "Epoch 4/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.8577 - acc: 0.7029 - val_loss: 1.1245 - val_acc: 0.6442\n",
      "Epoch 5/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.7967 - acc: 0.7263 - val_loss: 0.6581 - val_acc: 0.7685\n",
      "Epoch 6/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.7466 - acc: 0.7426 - val_loss: 0.6970 - val_acc: 0.7609\n",
      "Epoch 7/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.7083 - acc: 0.7565 - val_loss: 0.8468 - val_acc: 0.7247\n",
      "Epoch 8/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.6776 - acc: 0.7679 - val_loss: 0.6085 - val_acc: 0.7920\n",
      "Epoch 9/50\n",
      "1562/1562 [==============================] - 60s 38ms/step - loss: 0.6537 - acc: 0.7770 - val_loss: 0.5799 - val_acc: 0.8058\n",
      "Epoch 10/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.6330 - acc: 0.7832 - val_loss: 0.7001 - val_acc: 0.7675\n",
      "Epoch 11/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.6146 - acc: 0.7908 - val_loss: 0.5166 - val_acc: 0.8229\n",
      "Epoch 12/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.6005 - acc: 0.7956 - val_loss: 0.6557 - val_acc: 0.7914\n",
      "Epoch 13/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.5895 - acc: 0.7990 - val_loss: 0.5643 - val_acc: 0.8107\n",
      "Epoch 14/50\n",
      "1562/1562 [==============================] - 60s 38ms/step - loss: 0.5742 - acc: 0.8045 - val_loss: 0.7796 - val_acc: 0.7745\n",
      "Epoch 15/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.5641 - acc: 0.8070 - val_loss: 0.6258 - val_acc: 0.7997\n",
      "Epoch 16/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.5559 - acc: 0.8108 - val_loss: 0.5945 - val_acc: 0.8054\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 17/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.5051 - acc: 0.8267 - val_loss: 0.4720 - val_acc: 0.8401\n",
      "Epoch 18/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.4936 - acc: 0.8306 - val_loss: 0.4362 - val_acc: 0.8521\n",
      "Epoch 19/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.4870 - acc: 0.8325 - val_loss: 0.5006 - val_acc: 0.8312\n",
      "Epoch 20/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.4787 - acc: 0.8347 - val_loss: 0.4842 - val_acc: 0.8376\n",
      "Epoch 21/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.4750 - acc: 0.8366 - val_loss: 0.5627 - val_acc: 0.8120\n",
      "Epoch 22/50\n",
      "1562/1562 [==============================] - 60s 39ms/step - loss: 0.4662 - acc: 0.8395 - val_loss: 0.4550 - val_acc: 0.8481\n",
      "Epoch 23/50\n",
      "1562/1562 [==============================] - 60s 39ms/step - loss: 0.4632 - acc: 0.8407 - val_loss: 0.4133 - val_acc: 0.8636\n",
      "Epoch 24/50\n",
      "1562/1562 [==============================] - 60s 39ms/step - loss: 0.4598 - acc: 0.8418 - val_loss: 0.4331 - val_acc: 0.8553\n",
      "Epoch 25/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.4553 - acc: 0.8431 - val_loss: 0.4047 - val_acc: 0.8647\n",
      "Epoch 26/50\n",
      "1562/1562 [==============================] - 60s 39ms/step - loss: 0.4509 - acc: 0.8445 - val_loss: 0.4590 - val_acc: 0.8505\n",
      "Epoch 27/50\n",
      "1562/1562 [==============================] - 60s 39ms/step - loss: 0.4493 - acc: 0.8456 - val_loss: 0.4567 - val_acc: 0.8468\n",
      "Epoch 28/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.4474 - acc: 0.8469 - val_loss: 0.4802 - val_acc: 0.8432\n",
      "Epoch 29/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.4420 - acc: 0.8482 - val_loss: 0.4493 - val_acc: 0.8499\n",
      "Epoch 30/50\n",
      "1562/1562 [==============================] - 60s 39ms/step - loss: 0.4385 - acc: 0.8493 - val_loss: 0.4575 - val_acc: 0.8508\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 31/50\n",
      "1562/1562 [==============================] - 59s 38ms/step - loss: 0.4185 - acc: 0.8556 - val_loss: 0.4095 - val_acc: 0.8665\n",
      "Epoch 32/50\n",
      "1562/1562 [==============================] - 60s 39ms/step - loss: 0.4093 - acc: 0.8586 - val_loss: 0.4114 - val_acc: 0.8674\n",
      "Epoch 33/50\n",
      "1562/1562 [==============================] - 60s 39ms/step - loss: 0.4088 - acc: 0.8594 - val_loss: 0.4259 - val_acc: 0.8589\n",
      "Epoch 34/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.4065 - acc: 0.8600 - val_loss: 0.4099 - val_acc: 0.8658\n",
      "Epoch 35/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.4040 - acc: 0.8601 - val_loss: 0.3828 - val_acc: 0.8715\n",
      "Epoch 36/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.4017 - acc: 0.8607 - val_loss: 0.4420 - val_acc: 0.8575\n",
      "Epoch 37/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.3995 - acc: 0.8621 - val_loss: 0.4417 - val_acc: 0.8567\n",
      "Epoch 38/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.3970 - acc: 0.8625 - val_loss: 0.4174 - val_acc: 0.8631\n",
      "Epoch 39/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.3946 - acc: 0.8638 - val_loss: 0.4071 - val_acc: 0.8681\n",
      "Epoch 40/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.3932 - acc: 0.8647 - val_loss: 0.4198 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 41/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.3845 - acc: 0.8671 - val_loss: 0.3796 - val_acc: 0.8736\n",
      "Epoch 42/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.3787 - acc: 0.8693 - val_loss: 0.4059 - val_acc: 0.8666\n",
      "Epoch 43/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.3788 - acc: 0.8692 - val_loss: 0.3761 - val_acc: 0.8775\n",
      "Epoch 44/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.3780 - acc: 0.8699 - val_loss: 0.4194 - val_acc: 0.8649\n",
      "Epoch 45/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.3756 - acc: 0.8700 - val_loss: 0.3969 - val_acc: 0.8677\n",
      "Epoch 46/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.3760 - acc: 0.8706 - val_loss: 0.3913 - val_acc: 0.8727\n",
      "Epoch 47/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.3736 - acc: 0.8704 - val_loss: 0.4028 - val_acc: 0.8677\n",
      "Epoch 48/50\n",
      "1562/1562 [==============================] - 60s 39ms/step - loss: 0.3735 - acc: 0.8708 - val_loss: 0.3907 - val_acc: 0.8748\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 49/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.3677 - acc: 0.8734 - val_loss: 0.3945 - val_acc: 0.8725\n",
      "Epoch 50/50\n",
      "1562/1562 [==============================] - 61s 39ms/step - loss: 0.3667 - acc: 0.8726 - val_loss: 0.3903 - val_acc: 0.8744\n",
      "Test loss: 0.3903065531492233\n",
      "Test accuracy: 0.8744\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-3),\n",
    "              metrics=['accuracy'])\n",
    "#使用分批資料訓練模型\n",
    "\n",
    "model.fit_generator(data_generator.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=int(len(x_train) /32),\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test,y_test),\n",
    "                    \n",
    "                   callbacks=[earlystop,reduce_lr])\n",
    "    \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
